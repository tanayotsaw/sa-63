'use strict';

Object.defineProperty(exports, '__esModule', { value: true });

function _interopDefault (ex) { return (ex && (typeof ex === 'object') && 'default' in ex) ? ex['default'] : ex; }

var backendCommon = require('@backstage/backend-common');
var catalogModel = require('@backstage/catalog-model');
var lodash2 = _interopDefault(require('lodash'));
var Knex = _interopDefault(require('knex'));
var uuid = require('uuid');
var config = require('@backstage/config');
var fs = _interopDefault(require('fs-extra'));
var fetch = _interopDefault(require('node-fetch'));
var yaml2 = _interopDefault(require('yaml'));
var express2 = _interopDefault(require('express'));
var Router = _interopDefault(require('express-promise-router'));

class DatabaseEntitiesCatalog {
  constructor(database) {
    this.database = database;
  }
  async entities(filters) {
    const items = await this.database.transaction((tx) => this.database.entities(tx, filters));
    return items.map((i) => i.entity);
  }
  async entityByUid(uid) {
    const matches = await this.database.transaction((tx) => this.database.entities(tx, [{key: "uid", values: [uid]}]));
    return matches.length ? matches[0].entity : void 0;
  }
  async entityByName(kind, namespace, name) {
    const response = await this.database.transaction((tx) => this.entityByNameInternal(tx, kind, name, namespace));
    return response == null ? void 0 : response.entity;
  }
  async addOrUpdateEntity(entity, locationId) {
    return await this.database.transaction(async (tx) => {
      const existing = entity.metadata.uid ? await this.database.entityByUid(tx, entity.metadata.uid) : await this.entityByNameInternal(tx, entity.kind, entity.metadata.name, entity.metadata.namespace);
      let response;
      if (existing) {
        const updated = catalogModel.generateUpdatedEntity(existing.entity, entity);
        response = await this.database.updateEntity(tx, {locationId, entity: updated}, existing.entity.metadata.etag, existing.entity.metadata.generation);
      } else {
        response = await this.database.addEntity(tx, {locationId, entity});
      }
      return response.entity;
    });
  }
  async removeEntityByUid(uid) {
    return await this.database.transaction(async (tx) => {
      var _a;
      const entityResponse = await this.database.entityByUid(tx, uid);
      if (!entityResponse) {
        throw new backendCommon.NotFoundError(`Entity with ID ${uid} was not found`);
      }
      const location = (_a = entityResponse.entity.metadata.annotations) == null ? void 0 : _a[catalogModel.LOCATION_ANNOTATION];
      const colocatedEntities = location ? await this.database.entities(tx, [
        {
          key: catalogModel.LOCATION_ANNOTATION,
          values: [location]
        }
      ]) : [entityResponse];
      for (const dbResponse of colocatedEntities) {
        await this.database.removeEntity(tx, dbResponse == null ? void 0 : dbResponse.entity.metadata.uid);
      }
      if (entityResponse.locationId) {
        await this.database.removeLocation(tx, entityResponse == null ? void 0 : entityResponse.locationId);
      }
      return void 0;
    });
  }
  async entityByNameInternal(tx, kind, name, namespace) {
    const matches = await this.database.entities(tx, [
      {key: "kind", values: [kind]},
      {key: "name", values: [name]},
      {
        key: "namespace",
        values: !namespace || namespace === "default" ? [null, "default"] : [namespace]
      }
    ]);
    return matches.length ? matches[0] : void 0;
  }
}

var DatabaseLocationUpdateLogStatus;
(function(DatabaseLocationUpdateLogStatus2) {
  DatabaseLocationUpdateLogStatus2["FAIL"] = "fail";
  DatabaseLocationUpdateLogStatus2["SUCCESS"] = "success";
})(DatabaseLocationUpdateLogStatus || (DatabaseLocationUpdateLogStatus = {}));

class DatabaseLocationsCatalog {
  constructor(database) {
    this.database = database;
  }
  async addLocation(location) {
    const added = await this.database.addLocation(location);
    return added;
  }
  async removeLocation(id) {
    await this.database.transaction((tx) => this.database.removeLocation(tx, id));
  }
  async locations() {
    const items = await this.database.locations();
    return items.map(({message, status, timestamp, ...data}) => ({
      currentStatus: {
        message,
        status,
        timestamp
      },
      data
    }));
  }
  async locationHistory(id) {
    return this.database.locationHistory(id);
  }
  async location(id) {
    const {
      message,
      status,
      timestamp,
      ...data
    } = await this.database.location(id);
    return {
      currentStatus: {
        message,
        status,
        timestamp
      },
      data
    };
  }
  async logUpdateSuccess(locationId, entityName) {
    await this.database.addLocationUpdateLogEvent(locationId, DatabaseLocationUpdateLogStatus.SUCCESS, entityName);
  }
  async logUpdateFailure(locationId, error, entityName) {
    await this.database.addLocationUpdateLogEvent(locationId, DatabaseLocationUpdateLogStatus.FAIL, entityName, error == null ? void 0 : error.message);
  }
}

class StaticEntitiesCatalog {
  constructor(entities) {
    this._entities = entities;
  }
  async entities() {
    return lodash2.cloneDeep(this._entities);
  }
  async entityByUid(uid) {
    const item = this._entities.find((e) => uid === e.metadata.uid);
    return item ? lodash2.cloneDeep(item) : void 0;
  }
  async entityByName(kind, name, namespace) {
    const item = this._entities.find((e) => kind === e.kind && name === e.metadata.name && namespace === e.metadata.namespace);
    return item ? lodash2.cloneDeep(item) : void 0;
  }
  async addOrUpdateEntity() {
    throw new Error("Not supported");
  }
  async removeEntityByUid() {
    throw new Error("Not supported");
  }
}

const SHORTHAND_KEY_PREFIXES = [
  "metadata.",
  "metadata.labels.",
  "metadata.annotations.",
  "spec."
];
const SPECIAL_KEYS = [
  "metadata.name",
  "metadata.namespace",
  "metadata.uid",
  "metadata.etag",
  "metadata.generation"
];
function toValue(current) {
  if (current === void 0 || current === null) {
    return null;
  }
  return String(current);
}
function visitEntityPart(entityId, path, current, output) {
  if (SPECIAL_KEYS.includes(path)) {
    return;
  }
  if (current === void 0 || current === null || ["string", "number", "boolean"].includes(typeof current)) {
    output.push({entity_id: entityId, key: path, value: toValue(current)});
    return;
  }
  if (typeof current !== "object") {
    return;
  }
  if (Array.isArray(current)) {
    for (const item of current) {
      visitEntityPart(entityId, path, item, output);
    }
    return;
  }
  for (const [key, value] of Object.entries(current)) {
    visitEntityPart(entityId, path ? `${path}.${key}` : key, value, output);
  }
}
function buildEntitySearch(entityId, entity) {
  const result = [
    {
      entity_id: entityId,
      key: "metadata.name",
      value: toValue(entity.metadata.name)
    },
    {
      entity_id: entityId,
      key: "metadata.namespace",
      value: toValue(entity.metadata.namespace)
    },
    {
      entity_id: entityId,
      key: "metadata.uid",
      value: toValue(entity.metadata.uid)
    }
  ];
  visitEntityPart(entityId, "", entity, result);
  for (const row of result.slice()) {
    for (const stripPrefix of SHORTHAND_KEY_PREFIXES) {
      if (row.key.startsWith(stripPrefix)) {
        result.push({...row, key: row.key.substr(stripPrefix.length)});
      }
    }
  }
  return result;
}

class CommonDatabase {
  constructor(database, normalize, logger) {
    this.database = database;
    this.normalize = normalize;
    this.logger = logger;
  }
  async transaction(fn) {
    try {
      return await this.database.transaction(fn);
    } catch (e) {
      this.logger.debug(`Error during transaction, ${e}`);
      if (/SQLITE_CONSTRAINT: UNIQUE/.test(e.message) || /unique constraint/.test(e.message)) {
        throw new backendCommon.ConflictError(`Rejected due to a conflicting entity`, e);
      }
      throw e;
    }
  }
  async addEntity(txOpaque, request) {
    const tx = txOpaque;
    if (request.entity.metadata.uid !== void 0) {
      throw new backendCommon.InputError("May not specify uid for new entities");
    } else if (request.entity.metadata.etag !== void 0) {
      throw new backendCommon.InputError("May not specify etag for new entities");
    } else if (request.entity.metadata.generation !== void 0) {
      throw new backendCommon.InputError("May not specify generation for new entities");
    }
    await this.ensureNoSimilarNames(tx, request.entity);
    const newEntity = lodash2.cloneDeep(request.entity);
    newEntity.metadata = {
      ...newEntity.metadata,
      uid: catalogModel.generateEntityUid(),
      etag: catalogModel.generateEntityEtag(),
      generation: 1
    };
    const newRow = this.toEntityRow(request.locationId, newEntity);
    await tx("entities").insert(newRow);
    await this.updateEntitiesSearch(tx, newRow.id, newEntity);
    return {locationId: request.locationId, entity: newEntity};
  }
  async updateEntity(txOpaque, request, matchingEtag, matchingGeneration) {
    const tx = txOpaque;
    const {uid} = request.entity.metadata;
    if (uid === void 0) {
      throw new backendCommon.InputError("Must specify uid when updating entities");
    }
    const oldRows = await tx("entities").where({id: uid}).select();
    if (oldRows.length !== 1) {
      throw new backendCommon.NotFoundError("No matching entity found");
    }
    const oldRow = oldRows[0];
    oldRow.generation = Number(oldRow.generation);
    if (matchingEtag) {
      if (matchingEtag !== oldRow.etag) {
        throw new backendCommon.ConflictError(`Etag mismatch, expected="${matchingEtag}" found="${oldRow.etag}"`);
      }
    }
    if (matchingGeneration) {
      if (matchingGeneration !== oldRow.generation) {
        throw new backendCommon.ConflictError(`Generation mismatch, expected="${matchingGeneration}" found="${oldRow.generation}"`);
      }
    }
    await this.ensureNoSimilarNames(tx, request.entity);
    const newRow = this.toEntityRow(request.locationId, request.entity);
    const updatedRows = await tx("entities").where({id: oldRow.id, etag: oldRow.etag}).update(newRow);
    if (updatedRows !== 1) {
      throw new backendCommon.ConflictError(`Failed to update entity`);
    }
    await this.updateEntitiesSearch(tx, oldRow.id, request.entity);
    return request;
  }
  async entities(txOpaque, filters) {
    const tx = txOpaque;
    let builder = tx("entities");
    for (const [indexU, filter] of (filters != null ? filters : []).entries()) {
      const index = Number(indexU);
      const key = filter.key.replace("*", "%");
      const keyOp = filter.key.includes("*") ? "like" : "=";
      let matchNulls = false;
      const matchIn = [];
      const matchLike = [];
      for (const value of filter.values) {
        if (!value) {
          matchNulls = true;
        } else if (value.includes("*")) {
          matchLike.push(value.replace("*", "%"));
        } else {
          matchIn.push(value);
        }
      }
      builder = builder.leftOuterJoin(`entities_search as t${index}`, function joins() {
        this.on("entities.id", "=", `t${index}.entity_id`);
        this.andOn(`t${index}.key`, keyOp, tx.raw("?", [key]));
      }).where(function rules() {
        if (matchIn.length) {
          this.orWhereIn(`t${index}.value`, matchIn);
        }
        if (matchLike.length) {
          for (const x of matchLike) {
            this.orWhere(`t${index}.value`, "like", tx.raw("?", [x]));
          }
        }
        if (matchNulls) {
          this.orWhereNull(`t${index}.value`);
        }
      });
    }
    const rows = await builder.select("entities.*").orderBy("kind", "asc").orderBy("namespace", "asc").orderBy("name", "asc").groupBy("id");
    return rows.map((row) => this.toEntityResponse(row));
  }
  async entity(txOpaque, kind, name, namespace) {
    const tx = txOpaque;
    const rows = await tx("entities").where({kind, name, namespace: namespace || null}).select();
    if (rows.length !== 1) {
      return void 0;
    }
    return this.toEntityResponse(rows[0]);
  }
  async entityByUid(txOpaque, id) {
    const tx = txOpaque;
    const rows = await tx("entities").where({id}).select();
    if (rows.length !== 1) {
      return void 0;
    }
    return this.toEntityResponse(rows[0]);
  }
  async removeEntity(txOpaque, uid) {
    const tx = txOpaque;
    const result = await tx("entities").where({id: uid}).del();
    if (!result) {
      throw new backendCommon.NotFoundError(`Found no entity with ID ${uid}`);
    }
  }
  async addLocation(location) {
    return await this.database.transaction(async (tx) => {
      const row = {
        id: location.id,
        type: location.type,
        target: location.target
      };
      await tx("locations").insert(row);
      return row;
    });
  }
  async removeLocation(txOpaque, id) {
    const tx = txOpaque;
    await tx("entities").where({location_id: id}).update({location_id: null});
    const result = await tx("locations").where({id}).del();
    if (!result) {
      throw new backendCommon.NotFoundError(`Found no location with ID ${id}`);
    }
  }
  async location(id) {
    const items = await this.database("locations").where("locations.id", id).leftOuterJoin("location_update_log_latest", "locations.id", "location_update_log_latest.location_id").select("locations.*", {
      status: "location_update_log_latest.status",
      timestamp: "location_update_log_latest.created_at",
      message: "location_update_log_latest.message"
    });
    if (!items.length) {
      throw new backendCommon.NotFoundError(`Found no location with ID ${id}`);
    }
    return items[0];
  }
  async locations() {
    const locations = await this.database("locations").leftOuterJoin("location_update_log_latest", "locations.id", "location_update_log_latest.location_id").select("locations.*", {
      status: "location_update_log_latest.status",
      timestamp: "location_update_log_latest.created_at",
      message: "location_update_log_latest.message"
    });
    return locations;
  }
  async locationHistory(id) {
    const result = await this.database("location_update_log").where("location_id", id).orderBy("created_at", "desc").limit(10).select();
    return result;
  }
  async addLocationUpdateLogEvent(locationId, status, entityName, message) {
    return this.database("location_update_log").insert({
      status,
      location_id: locationId,
      entity_name: entityName,
      message
    });
  }
  async updateEntitiesSearch(tx, entityId, data) {
    try {
      const entries = buildEntitySearch(entityId, data);
      await tx("entities_search").where({entity_id: entityId}).del();
      await tx("entities_search").insert(entries);
    } catch {
    }
  }
  async ensureNoSimilarNames(tx, data) {
    const newKind = data.kind;
    const newName = data.metadata.name;
    const newNamespace = data.metadata.namespace;
    const newKindNorm = this.normalize(newKind);
    const newNameNorm = this.normalize(newName);
    const newNamespaceNorm = this.normalize(newNamespace || "");
    for (const item of await this.entities(tx)) {
      if (data.metadata.uid === item.entity.metadata.uid) {
        continue;
      }
      const oldKind = item.entity.kind;
      const oldName = item.entity.metadata.name;
      const oldNamespace = item.entity.metadata.namespace;
      const oldKindNorm = this.normalize(oldKind);
      const oldNameNorm = this.normalize(oldName);
      const oldNamespaceNorm = this.normalize(oldNamespace || "");
      if (oldKindNorm === newKindNorm && oldNameNorm === newNameNorm && oldNamespaceNorm === newNamespaceNorm) {
        if (oldKind !== newKind || oldName !== newName || oldNamespace !== newNamespace) {
          const message = `Kind, namespace, name are too similar to an existing entity`;
          throw new backendCommon.ConflictError(message);
        }
      }
    }
  }
  toEntityRow(locationId, entity) {
    return {
      id: entity.metadata.uid,
      location_id: locationId || null,
      etag: entity.metadata.etag,
      generation: entity.metadata.generation,
      api_version: entity.apiVersion,
      kind: entity.kind,
      name: entity.metadata.name,
      namespace: entity.metadata.namespace || null,
      metadata: JSON.stringify(lodash2.omit(entity.metadata, ...catalogModel.entityMetaGeneratedFields)),
      spec: entity.spec ? JSON.stringify(entity.spec) : null
    };
  }
  toEntityResponse(row) {
    const entity = {
      apiVersion: row.api_version,
      kind: row.kind,
      metadata: {
        ...JSON.parse(row.metadata),
        uid: row.id,
        etag: row.etag,
        generation: Number(row.generation)
      }
    };
    if (row.spec) {
      const spec = JSON.parse(row.spec);
      entity.spec = spec;
    }
    return {
      locationId: row.location_id || void 0,
      entity
    };
  }
}

const migrationsDir = backendCommon.resolvePackagePath("@backstage/plugin-catalog-backend", "migrations");
const defaultOptions = {
  logger: backendCommon.getVoidLogger(),
  fieldNormalizer: catalogModel.makeValidator().normalizeEntityName
};
class DatabaseManager {
  static async createDatabase(knex2, options = {}) {
    await knex2.migrate.latest({
      directory: migrationsDir
    });
    const {logger, fieldNormalizer} = {...defaultOptions, ...options};
    return new CommonDatabase(knex2, fieldNormalizer, logger);
  }
  static async createInMemoryDatabase(options = {}) {
    const knex2 = Knex({
      client: "sqlite3",
      connection: ":memory:",
      useNullAsDefault: true
    });
    knex2.client.pool.on("createSuccess", (_eventId, resource) => {
      resource.run("PRAGMA foreign_keys = ON", () => {
      });
    });
    return DatabaseManager.createDatabase(knex2, options);
  }
  static async createTestDatabase() {
    const knex2 = Knex({
      client: "sqlite3",
      connection: ":memory:",
      useNullAsDefault: true
    });
    knex2.client.pool.on("createSuccess", (_eventId, resource) => {
      resource.run("PRAGMA foreign_keys = ON", () => {
      });
    });
    await knex2.migrate.latest({
      directory: migrationsDir
    });
    const {logger, fieldNormalizer} = defaultOptions;
    return new CommonDatabase(knex2, fieldNormalizer, logger);
  }
}

class HigherOrderOperations {
  constructor(entitiesCatalog, locationsCatalog, locationReader, logger) {
    this.entitiesCatalog = entitiesCatalog;
    this.locationsCatalog = locationsCatalog;
    this.locationReader = locationReader;
    this.logger = logger;
  }
  async addLocation(spec) {
    const previousLocations = await this.locationsCatalog.locations();
    const previousLocation = previousLocations.find((l) => spec.type === l.data.type && spec.target === l.data.target);
    const location = previousLocation ? previousLocation.data : {
      id: uuid.v4(),
      type: spec.type,
      target: spec.target
    };
    const readerOutput = await this.locationReader.read(spec);
    if (readerOutput.errors.length) {
      const item = readerOutput.errors[0];
      throw new backendCommon.InputError(`Failed to read location ${item.location.type} ${item.location.target}, ${item.error}`);
    }
    if (!previousLocation) {
      await this.locationsCatalog.addLocation(location);
    }
    const outputEntities = [];
    for (const entity of readerOutput.entities) {
      const out = await this.entitiesCatalog.addOrUpdateEntity(entity.entity, location.id);
      outputEntities.push(out);
    }
    return {location, entities: outputEntities};
  }
  async refreshAllLocations() {
    const startTimestamp = new Date().valueOf();
    this.logger.info("Beginning locations refresh");
    const locations = await this.locationsCatalog.locations();
    this.logger.info(`Visiting ${locations.length} locations`);
    for (const {data: location} of locations) {
      this.logger.debug(`Refreshing location id="${location.id}" type="${location.type}" target="${location.target}"`);
      try {
        await this.refreshSingleLocation(location);
        await this.locationsCatalog.logUpdateSuccess(location.id, void 0);
      } catch (e) {
        this.logger.debug(`Failed to refresh location id="${location.id}" type="${location.type}" target="${location.target}", ${e}`);
        await this.locationsCatalog.logUpdateFailure(location.id, e);
      }
    }
    const endTimestamp = new Date().valueOf();
    const duration = ((endTimestamp - startTimestamp) / 1e3).toFixed(1);
    this.logger.debug(`Completed locations refresh in ${duration} seconds`);
  }
  async refreshSingleLocation(location) {
    const readerOutput = await this.locationReader.read({
      type: location.type,
      target: location.target
    });
    for (const item of readerOutput.errors) {
      this.logger.debug(`Failed item in location type="${item.location.type}" target="${item.location.target}", ${item.error}`);
    }
    for (const item of readerOutput.entities) {
      const {entity} = item;
      this.logger.debug(`Read entity kind="${entity.kind}" name="${entity.metadata.name}" namespace="${entity.metadata.namespace || ""}"`);
      try {
        const previous = await this.entitiesCatalog.entityByName(entity.kind, entity.metadata.namespace, entity.metadata.name);
        if (!previous) {
          this.logger.debug(`No such entity found, adding`);
          await this.entitiesCatalog.addOrUpdateEntity(entity, location.id);
        } else if (catalogModel.entityHasChanges(previous, entity)) {
          this.logger.debug(`Different from existing entity, updating`);
          await this.entitiesCatalog.addOrUpdateEntity(entity, location.id);
        } else {
          this.logger.debug(`Equal to existing entity, skipping update`);
        }
        await this.locationsCatalog.logUpdateSuccess(location.id, entity.metadata.name);
      } catch (error) {
        this.logger.debug(`Failed refresh of entity kind="${entity.kind}" name="${entity.metadata.name}" namespace="${entity.metadata.namespace || ""}", ${error}`);
        await this.locationsCatalog.logUpdateFailure(location.id, error, entity.metadata.name);
      }
    }
  }
}

class AnnotateLocationEntityProcessor {
  async processEntity(entity, location) {
    return lodash2.merge({
      metadata: {
        annotations: {
          "backstage.io/managed-by-location": `${location.type}:${location.target}`
        }
      }
    }, entity);
  }
}

class EntityPolicyProcessor {
  constructor(policy) {
    this.policy = policy;
  }
  async processEntity(entity) {
    return await this.policy.enforce(entity);
  }
}

function notFoundError(atLocation, message) {
  return {
    type: "error",
    location: atLocation,
    error: new backendCommon.NotFoundError(message)
  };
}
function inputError(atLocation, message) {
  return {
    type: "error",
    location: atLocation,
    error: new backendCommon.InputError(message)
  };
}
function generalError(atLocation, message) {
  return {type: "error", location: atLocation, error: new Error(message)};
}
function data(atLocation, newData) {
  return {type: "data", location: atLocation, data: newData};
}
function location(newLocation, optional) {
  return {type: "location", location: newLocation, optional};
}
function entity(atLocation, newEntity) {
  return {type: "entity", location: atLocation, entity: newEntity};
}

var results = /*#__PURE__*/Object.freeze({
  __proto__: null,
  notFoundError: notFoundError,
  inputError: inputError,
  generalError: generalError,
  data: data,
  location: location,
  entity: entity
});

class FileReaderProcessor {
  async readLocation(location, optional, emit) {
    if (location.type !== "file") {
      return false;
    }
    try {
      const exists = await fs.pathExists(location.target);
      if (exists) {
        const data2 = await fs.readFile(location.target);
        emit(data(location, data2));
      } else if (!optional) {
        const message = `${location.type} ${location.target} does not exist`;
        emit(notFoundError(location, message));
      }
    } catch (e) {
      const message = `${location.type} ${location.target} could not be read, ${e}`;
      emit(generalError(location, message));
    }
    return true;
  }
}

class GithubReaderProcessor {
  async readLocation(location, optional, emit) {
    if (location.type !== "github") {
      return false;
    }
    try {
      const url = this.buildRawUrl(location.target);
      const response = await fetch(url.toString());
      if (response.ok) {
        const data2 = await response.buffer();
        emit(data(location, data2));
      } else {
        const message = `${location.target} could not be read as ${url}, ${response.status} ${response.statusText}`;
        if (response.status === 404) {
          if (!optional) {
            emit(notFoundError(location, message));
          }
        } else {
          emit(generalError(location, message));
        }
      }
    } catch (e) {
      const message = `Unable to read ${location.type} ${location.target}, ${e}`;
      emit(generalError(location, message));
    }
    return true;
  }
  buildRawUrl(target) {
    try {
      const url = new URL(target);
      const [
        empty,
        userOrOrg,
        repoName,
        blobKeyword,
        ...restOfPath
      ] = url.pathname.split("/");
      if (url.hostname !== "github.com" || empty !== "" || userOrOrg === "" || repoName === "" || blobKeyword !== "blob" || !restOfPath.join("/").match(/\.yaml$/)) {
        throw new Error("Wrong GitHub URL");
      }
      url.pathname = [empty, userOrOrg, repoName, ...restOfPath].join("/");
      url.hostname = "raw.githubusercontent.com";
      url.protocol = "https";
      return url;
    } catch (e) {
      throw new Error(`Incorrect url: ${target}, ${e}`);
    }
  }
}

class GithubApiReaderProcessor {
  constructor(config2) {
    var _a;
    this.privateToken = (_a = config2.getOptionalString("catalog.processors.githubApi.privateToken")) != null ? _a : "";
  }
  getRequestOptions() {
    const headers = {
      Accept: "application/vnd.github.v3.raw"
    };
    if (this.privateToken !== "") {
      headers.Authorization = `token ${this.privateToken}`;
    }
    const requestOptions = {
      headers
    };
    return requestOptions;
  }
  async readLocation(location, optional, emit) {
    if (location.type !== "github/api") {
      return false;
    }
    try {
      const url = this.buildRawUrl(location.target);
      const response = await fetch(url.toString(), this.getRequestOptions());
      if (response.ok) {
        const data2 = await response.buffer();
        emit(data(location, data2));
      } else {
        const message = `${location.target} could not be read as ${url}, ${response.status} ${response.statusText}`;
        if (response.status === 404) {
          if (!optional) {
            emit(notFoundError(location, message));
          }
        } else {
          emit(generalError(location, message));
        }
      }
    } catch (e) {
      const message = `Unable to read ${location.type} ${location.target}, ${e}`;
      emit(generalError(location, message));
    }
    return true;
  }
  buildRawUrl(target) {
    try {
      const url = new URL(target);
      const [
        empty,
        userOrOrg,
        repoName,
        blobKeyword,
        ref,
        ...restOfPath
      ] = url.pathname.split("/");
      if (url.hostname !== "github.com" || empty !== "" || userOrOrg === "" || repoName === "" || blobKeyword !== "blob" || !restOfPath.join("/").match(/\.yaml$/)) {
        throw new Error("Wrong GitHub URL or Invalid file path");
      }
      url.pathname = [
        empty,
        "repos",
        userOrOrg,
        repoName,
        "contents",
        ...restOfPath
      ].join("/");
      url.hostname = "api.github.com";
      url.protocol = "https";
      url.search = `ref=${ref}`;
      return url;
    } catch (e) {
      throw new Error(`Incorrect url: ${target}, ${e}`);
    }
  }
}

class GitlabApiReaderProcessor {
  constructor(config2) {
    var _a;
    this.privateToken = (_a = config2.getOptionalString("catalog.processors.gitlabApi.privateToken")) != null ? _a : "";
  }
  getRequestOptions() {
    const headers = {"PRIVATE-TOKEN": ""};
    if (this.privateToken !== "") {
      headers["PRIVATE-TOKEN"] = this.privateToken;
    }
    const requestOptions = {
      headers
    };
    return requestOptions;
  }
  async readLocation(location, optional, emit) {
    if (location.type !== "gitlab/api") {
      return false;
    }
    try {
      const projectID = await this.getProjectID(location.target);
      const url = this.buildRawUrl(location.target, projectID);
      const response = await fetch(url.toString(), this.getRequestOptions());
      if (response.ok) {
        const data2 = await response.buffer();
        emit(data(location, data2));
      } else {
        const message = `${location.target} could not be read as ${url}, ${response.status} ${response.statusText}`;
        if (response.status === 404) {
          if (!optional) {
            emit(notFoundError(location, message));
          }
        } else {
          emit(generalError(location, message));
        }
      }
    } catch (e) {
      const message = `Unable to read ${location.type} ${location.target}, ${e}`;
      emit(generalError(location, message));
    }
    return true;
  }
  buildRawUrl(target, projectID) {
    try {
      const url = new URL(target);
      const branchAndfilePath = url.pathname.split("/-/blob/")[1];
      if (!branchAndfilePath.match(/\.ya?ml$/)) {
        throw new Error("GitLab url does not end in .ya?ml");
      }
      const [branch, ...filePath] = branchAndfilePath.split("/");
      url.pathname = [
        "/api/v4/projects",
        projectID,
        "repository/files",
        encodeURIComponent(filePath.join("/")),
        "raw"
      ].join("/");
      url.search = `?ref=${branch}`;
      return url;
    } catch (e) {
      throw new Error(`Incorrect url: ${target}, ${e}`);
    }
  }
  async getProjectID(target) {
    const url = new URL(target);
    if (!url.pathname.match(/\/\-\/blob\//)) {
      throw new Error("Please provide full path to yaml file from Gitlab");
    }
    try {
      const repo = url.pathname.split("/-/blob/")[0];
      const repoIDLookup = new URL(`${url.protocol + url.hostname}/api/v4/projects/${encodeURIComponent(repo.replace(/^\//, ""))}`);
      const response = await fetch(repoIDLookup.toString(), this.getRequestOptions());
      const projectIDJson = await response.json();
      const projectID = projectIDJson.id;
      return projectID;
    } catch (e) {
      throw new Error(`Could not get GitLab ProjectID for: ${target}, ${e}`);
    }
  }
}

class GitlabReaderProcessor {
  async readLocation(location, optional, emit) {
    if (location.type !== "gitlab") {
      return false;
    }
    try {
      const url = this.buildRawUrl(location.target);
      const response = await fetch(url.toString());
      if (response.ok) {
        const data2 = await response.buffer();
        emit(data(location, data2));
      } else {
        const message = `${location.target} could not be read as ${url}, ${response.status} ${response.statusText}`;
        if (response.status === 404) {
          if (!optional) {
            throw notFoundError(location, message);
          }
        } else {
          throw generalError(location, message);
        }
      }
    } catch (e) {
      const message = `Unable to read ${location.type} ${location.target}, ${e}`;
      emit(generalError(location, message));
    }
    return true;
  }
  buildRawUrl(target) {
    try {
      const url = new URL(target);
      const [
        empty,
        userOrOrg,
        repoName,
        blobKeyword,
        ...restOfPath
      ] = url.pathname.split("/");
      if (empty !== "" || userOrOrg === "" || repoName === "" || blobKeyword !== "blob" || !restOfPath.join("/").match(/\.yaml$/)) {
        throw new Error("Wrong GitLab URL");
      }
      url.pathname = [empty, userOrOrg, repoName, "raw", ...restOfPath].join("/");
      return url;
    } catch (e) {
      throw new Error(`Incorrect url: ${target}, ${e}`);
    }
  }
}

class BitbucketApiReaderProcessor {
  constructor(config2) {
    var _a, _b;
    this.username = (_a = config2.getOptionalString("catalog.processors.bitbucketApi.username")) != null ? _a : "";
    this.password = (_b = config2.getOptionalString("catalog.processors.bitbucketApi.appPassword")) != null ? _b : "";
  }
  getRequestOptions() {
    const headers = {};
    if (this.username !== "" && this.password !== "") {
      headers.Authorization = `Basic ${Buffer.from(`${this.username}:${this.password}`, "utf8").toString("base64")}`;
    }
    const requestOptions = {
      headers
    };
    return requestOptions;
  }
  async readLocation(location, optional, emit) {
    if (location.type !== "bitbucket/api") {
      return false;
    }
    try {
      const url = this.buildRawUrl(location.target);
      const response = await fetch(url.toString(), this.getRequestOptions());
      if (response.ok) {
        const data2 = await response.buffer();
        emit(data(location, data2));
      } else {
        const message = `${location.target} could not be read as ${url}, ${response.status} ${response.statusText}`;
        if (response.status === 404) {
          if (!optional) {
            emit(notFoundError(location, message));
          }
        } else {
          emit(generalError(location, message));
        }
      }
    } catch (e) {
      const message = `Unable to read ${location.type} ${location.target}, ${e}`;
      emit(generalError(location, message));
    }
    return true;
  }
  buildRawUrl(target) {
    try {
      const url = new URL(target);
      const [
        empty,
        userOrOrg,
        repoName,
        srcKeyword,
        ref,
        ...restOfPath
      ] = url.pathname.split("/");
      if (url.hostname !== "bitbucket.org" || empty !== "" || userOrOrg === "" || repoName === "" || srcKeyword !== "src" || !restOfPath.join("/").match(/\.yaml$/)) {
        throw new Error("Wrong Bitbucket URL or Invalid file path");
      }
      url.pathname = [
        empty,
        "2.0",
        "repositories",
        userOrOrg,
        repoName,
        "src",
        ref,
        ...restOfPath
      ].join("/");
      url.hostname = "api.bitbucket.org";
      url.protocol = "https";
      return url;
    } catch (e) {
      throw new Error(`Incorrect url: ${target}, ${e}`);
    }
  }
}

class AzureApiReaderProcessor {
  constructor(config2) {
    var _a;
    this.privateToken = (_a = config2.getOptionalString("catalog.processors.azureApi.privateToken")) != null ? _a : "";
  }
  getRequestOptions() {
    const headers = {};
    if (this.privateToken !== "") {
      headers.Authorization = `Basic ${Buffer.from(`:${this.privateToken}`, "utf8").toString("base64")}`;
    }
    const requestOptions = {
      headers
    };
    return requestOptions;
  }
  async readLocation(location, optional, emit) {
    if (location.type !== "azure/api") {
      return false;
    }
    try {
      const url = this.buildRawUrl(location.target);
      const response = await fetch(url.toString(), this.getRequestOptions());
      if (response.ok && response.status !== 203) {
        const data2 = await response.buffer();
        emit(data(location, data2));
      } else {
        const message = `${location.target} could not be read as ${url}, ${response.status} ${response.statusText}`;
        if (response.status === 404) {
          if (!optional) {
            emit(notFoundError(location, message));
          }
        } else {
          emit(generalError(location, message));
        }
      }
    } catch (e) {
      const message = `Unable to read ${location.type} ${location.target}, ${e}`;
      emit(generalError(location, message));
    }
    return true;
  }
  buildRawUrl(target) {
    var _a;
    try {
      const url = new URL(target);
      const [
        empty,
        userOrOrg,
        project,
        srcKeyword,
        repoName
      ] = url.pathname.split("/");
      const path = url.searchParams.get("path") || "";
      const ref = (_a = url.searchParams.get("version")) == null ? void 0 : _a.substr(2);
      if (url.hostname !== "dev.azure.com" || empty !== "" || userOrOrg === "" || project === "" || srcKeyword !== "_git" || repoName === "" || path === "" || ref === "" || !path.match(/\.yaml$/)) {
        throw new Error("Wrong Azure Devops URL or Invalid file path");
      }
      url.pathname = [
        empty,
        userOrOrg,
        project,
        "_apis",
        "sourceProviders",
        "TfsGit",
        "filecontents"
      ].join("/");
      url.search = [
        `repository=${repoName}`,
        `commitOrBranch=${ref}`,
        `path=${path}`,
        "api-version=6.0-preview.1"
      ].join("&");
      url.protocol = "https";
      return url;
    } catch (e) {
      throw new Error(`Incorrect url: ${target}, ${e}`);
    }
  }
}

class UrlReaderProcessor {
  async readLocation(location, optional, emit) {
    if (location.type !== "url") {
      return false;
    }
    try {
      const response = await fetch(location.target);
      if (response.ok) {
        const data2 = await response.buffer();
        emit(data(location, data2));
      } else {
        const message = `${location.target} could not be read, ${response.status} ${response.statusText}`;
        if (response.status === 404) {
          if (!optional) {
            emit(notFoundError(location, message));
          }
        } else {
          emit(generalError(location, message));
        }
      }
    } catch (e) {
      const message = `Unable to read ${location.type} ${location.target}, ${e}`;
      emit(generalError(location, message));
    }
    return true;
  }
}

class LocationRefProcessor {
  async processEntity(entity, _location, emit) {
    if (entity.kind === "Location") {
      const location2 = entity;
      if (location2.spec.target) {
        emit(location({type: location2.spec.type, target: location2.spec.target}, false));
      }
      if (location2.spec.targets) {
        for (const target of location2.spec.targets) {
          emit(location({type: location2.spec.type, target}, false));
        }
      }
    }
    return entity;
  }
}

class StaticLocationProcessor {
  constructor(staticLocations) {
    this.staticLocations = staticLocations;
  }
  static fromConfig(config2) {
    var _a;
    const locations = [];
    const lConfigs = (_a = config2.getOptionalConfigArray("catalog.locations")) != null ? _a : [];
    for (const lConfig of lConfigs) {
      const type = lConfig.getString("type");
      const target = lConfig.getString("target");
      locations.push({type, target});
    }
    return new StaticLocationProcessor(locations);
  }
  async readLocation(location2, _optional, emit) {
    if (location2.type !== "bootstrap") {
      return false;
    }
    for (const staticLocation of this.staticLocations) {
      emit(location(staticLocation, false));
    }
    return true;
  }
}

class YamlProcessor {
  async parseData(data, location, emit) {
    var _a;
    if (!location.target.match(/\.ya?ml/)) {
      return false;
    }
    let documents;
    try {
      documents = yaml2.parseAllDocuments(data.toString("utf8")).filter((d) => d);
    } catch (e) {
      emit(generalError(location, `Failed to parse YAML, ${e}`));
      return true;
    }
    for (const document of documents) {
      if ((_a = document.errors) == null ? void 0 : _a.length) {
        const message = `YAML error, ${document.errors[0]}`;
        emit(generalError(location, message));
      } else {
        const json = document.toJSON();
        if (lodash2.isPlainObject(json)) {
          emit(entity(location, json));
        } else {
          const message = `Expected object at root, got ${typeof json}`;
          emit(generalError(location, message));
        }
      }
    }
    return true;
  }
}

class CatalogRulesEnforcer {
  constructor(rules) {
    this.rules = rules;
  }
  static fromConfig(config2) {
    const rules = new Array();
    if (config2.has("catalog.rules")) {
      const globalRules = config2.getConfigArray("catalog.rules").map((sub) => ({
        allow: sub.getStringArray("allow").map((kind) => ({kind}))
      }));
      rules.push(...globalRules);
    } else {
      rules.push(...CatalogRulesEnforcer.defaultRules);
    }
    if (config2.has("catalog.locations")) {
      const locationRules = config2.getConfigArray("catalog.locations").flatMap((locConf) => {
        if (!locConf.has("rules")) {
          return [];
        }
        const type = locConf.getString("type");
        const target = locConf.getString("target");
        return locConf.getConfigArray("rules").map((ruleConf) => ({
          allow: ruleConf.getStringArray("allow").map((kind) => ({kind})),
          locations: [{type, target}]
        }));
      });
      rules.push(...locationRules);
    }
    return new CatalogRulesEnforcer(rules);
  }
  isAllowed(entity, location) {
    for (const rule of this.rules) {
      if (!this.matchLocation(location, rule.locations)) {
        continue;
      }
      if (this.matchEntity(entity, rule.allow)) {
        return true;
      }
    }
    return false;
  }
  matchLocation(location, matchers) {
    if (!matchers) {
      return true;
    }
    for (const matcher of matchers) {
      if (matcher.type !== location.type) {
        continue;
      }
      if (matcher.target && matcher.target !== location.target) {
        continue;
      }
      return true;
    }
    return false;
  }
  matchEntity(entity, matchers) {
    if (!matchers) {
      return true;
    }
    for (const matcher of matchers) {
      if (entity.kind.toLowerCase() !== matcher.kind.toLowerCase()) {
        continue;
      }
      return true;
    }
    return false;
  }
}
CatalogRulesEnforcer.defaultRules = [
  {
    allow: ["Component", "API", "Location"].map((kind) => ({kind}))
  }
];

const MAX_DEPTH = 10;
class LocationReaders {
  static defaultProcessors(options) {
    const {
      config: config2 = new config.ConfigReader({}, "missing-config"),
      entityPolicy = new catalogModel.EntityPolicies()
    } = options;
    return [
      StaticLocationProcessor.fromConfig(config2),
      new FileReaderProcessor(),
      new GithubReaderProcessor(),
      new GithubApiReaderProcessor(config2),
      new GitlabApiReaderProcessor(config2),
      new GitlabReaderProcessor(),
      new BitbucketApiReaderProcessor(config2),
      new AzureApiReaderProcessor(config2),
      new UrlReaderProcessor(),
      new YamlProcessor(),
      new EntityPolicyProcessor(entityPolicy),
      new LocationRefProcessor(),
      new AnnotateLocationEntityProcessor()
    ];
  }
  constructor({
    logger = backendCommon.getVoidLogger(),
    config: config2,
    processors = LocationReaders.defaultProcessors({config: config2})
  }) {
    this.logger = logger;
    this.processors = processors;
    this.rulesEnforcer = config2 ? CatalogRulesEnforcer.fromConfig(config2) : new CatalogRulesEnforcer(CatalogRulesEnforcer.defaultRules);
  }
  async read(location2) {
    const output = {entities: [], errors: []};
    let items = [location(location2, false)];
    for (let depth = 0; depth < MAX_DEPTH; ++depth) {
      const newItems = [];
      const emit = (i) => newItems.push(i);
      for (const item of items) {
        if (item.type === "location") {
          await this.handleLocation(item, emit);
        } else if (item.type === "data") {
          await this.handleData(item, emit);
        } else if (item.type === "entity") {
          if (this.rulesEnforcer.isAllowed(item.entity, item.location)) {
            const entity = await this.handleEntity(item, emit);
            output.entities.push({
              entity,
              location: item.location
            });
          } else {
            output.errors.push({
              location: item.location,
              error: new Error(`Entity of kind ${item.entity.kind} is not allowed from location ${item.location.target}:${item.location.type}`)
            });
          }
        } else if (item.type === "error") {
          await this.handleError(item, emit);
          output.errors.push({
            location: item.location,
            error: item.error
          });
        }
      }
      if (newItems.length === 0) {
        return output;
      }
      items = newItems;
    }
    const message = `Max recursion depth ${MAX_DEPTH} reached for ${location2.type} ${location2.target}`;
    this.logger.warn(message);
    output.errors.push({location: location2, error: new Error(message)});
    return output;
  }
  async handleLocation(item, emit) {
    this.logger.debug(`Reading location ${item.location.type} ${item.location.target} optional=${item.optional}`);
    for (const processor of this.processors) {
      if (processor.readLocation) {
        try {
          if (await processor.readLocation(item.location, item.optional, emit)) {
            return;
          }
        } catch (e) {
          const message2 = `Processor ${processor.constructor.name} threw an error while reading location ${item.location.type} ${item.location.target}, ${e}`;
          emit(generalError(item.location, message2));
        }
      }
    }
    const message = `No processor was able to read location ${item.location.type} ${item.location.target}`;
    emit(inputError(item.location, message));
  }
  async handleData(item, emit) {
    this.logger.debug(`Parsing data from location ${item.location.type} ${item.location.target} (${item.data.byteLength} bytes)`);
    for (const processor of this.processors) {
      if (processor.parseData) {
        try {
          if (await processor.parseData(item.data, item.location, emit)) {
            return;
          }
        } catch (e) {
          const message2 = `Processor ${processor.constructor.name} threw an error while parsing ${item.location.type} ${item.location.target}, ${e}`;
          emit(generalError(item.location, message2));
        }
      }
    }
    const message = `No processor was able to parse location ${item.location.type} ${item.location.target}`;
    emit(inputError(item.location, message));
  }
  async handleEntity(item, emit) {
    this.logger.debug(`Got entity at location ${item.location.type} ${item.location.target}, ${item.entity.apiVersion} ${item.entity.kind}`);
    let current = item.entity;
    for (const processor of this.processors) {
      if (processor.processEntity) {
        try {
          current = await processor.processEntity(current, item.location, emit);
        } catch (e) {
          const message = `Processor ${processor.constructor.name} threw an error while processing entity at ${item.location.type} ${item.location.target}, ${e}`;
          emit(generalError(item.location, message));
        }
      }
    }
    return current;
  }
  async handleError(item, emit) {
    this.logger.debug(`Encountered error at location ${item.location.type} ${item.location.target}, ${item.error}`);
    for (const processor of this.processors) {
      if (processor.handleError) {
        try {
          await processor.handleError(item.error, item.location, emit);
        } catch (e) {
          const message = `Processor ${processor.constructor.name} threw an error while handling another error at ${item.location.type} ${item.location.target}, ${e}`;
          emit(generalError(item.location, message));
        }
      }
    }
  }
}

async function requireRequestBody(req) {
  const contentType = req.header("content-type");
  if (!contentType) {
    throw new backendCommon.InputError("Content-Type missing");
  } else if (!contentType.match(/^application\/json($|;)/)) {
    throw new backendCommon.InputError("Illegal Content-Type");
  }
  const body = req.body;
  if (!body) {
    throw new backendCommon.InputError("Missing request body");
  } else if (!lodash2.isPlainObject(body)) {
    throw new backendCommon.InputError("Expected body to be a JSON object");
  } else if (Object.keys(body).length === 0) {
    throw new backendCommon.InputError("Empty request body");
  }
  return body;
}
async function validateRequestBody(req, schema) {
  const body = await requireRequestBody(req);
  try {
    await schema.validate(body, {strict: true});
  } catch (e) {
    throw new backendCommon.InputError(`Malformed request: ${e}`);
  }
  return body;
}

async function createRouter(options) {
  const {entitiesCatalog, locationsCatalog, higherOrderOperation} = options;
  const router = Router();
  router.use(express2.json());
  if (entitiesCatalog) {
    router.get("/entities", async (req, res) => {
      const filters = translateQueryToEntityFilters(req);
      const entities = await entitiesCatalog.entities(filters);
      res.status(200).send(entities);
    }).post("/entities", async (req, res) => {
      const body = await requireRequestBody(req);
      const result = await entitiesCatalog.addOrUpdateEntity(body);
      res.status(200).send(result);
    }).get("/entities/by-uid/:uid", async (req, res) => {
      const {uid} = req.params;
      const entity = await entitiesCatalog.entityByUid(uid);
      if (!entity) {
        res.status(404).send(`No entity with uid ${uid}`);
      }
      res.status(200).send(entity);
    }).delete("/entities/by-uid/:uid", async (req, res) => {
      const {uid} = req.params;
      await entitiesCatalog.removeEntityByUid(uid);
      res.status(204).send();
    }).get("/entities/by-name/:kind/:namespace/:name", async (req, res) => {
      const {kind, namespace, name} = req.params;
      const entity = await entitiesCatalog.entityByName(kind, namespace, name);
      if (!entity) {
        res.status(404).send(`No entity with kind ${kind} namespace ${namespace} name ${name}`);
      }
      res.status(200).send(entity);
    });
  }
  if (higherOrderOperation) {
    router.post("/locations", async (req, res) => {
      const input = await validateRequestBody(req, catalogModel.locationSpecSchema);
      const output = await higherOrderOperation.addLocation(input);
      res.status(201).send(output);
    });
  }
  if (locationsCatalog) {
    router.get("/locations", async (_req, res) => {
      const output = await locationsCatalog.locations();
      res.status(200).send(output);
    }).get("/locations/:id/history", async (req, res) => {
      const {id} = req.params;
      const output = await locationsCatalog.locationHistory(id);
      res.status(200).send(output);
    }).get("/locations/:id", async (req, res) => {
      const {id} = req.params;
      const output = await locationsCatalog.location(id);
      res.status(200).send(output);
    }).delete("/locations/:id", async (req, res) => {
      const {id} = req.params;
      await locationsCatalog.removeLocation(id);
      res.status(204).send();
    });
  }
  router.use(backendCommon.errorHandler());
  return router;
}
function translateQueryToEntityFilters(request) {
  const filters = [];
  for (const [key, valueOrValues] of Object.entries(request.query)) {
    const values = Array.isArray(valueOrValues) ? valueOrValues : [valueOrValues];
    if (values.some((v) => typeof v !== "string")) {
      throw new backendCommon.InputError("Complex query parameters are not supported");
    }
    filters.push({
      key,
      values: values.map((v) => v || null)
    });
  }
  return filters;
}

function runPeriodically(fn, delayMs) {
  let cancel;
  let cancelled = false;
  const cancellationPromise = new Promise((resolve) => {
    cancel = () => {
      resolve();
      cancelled = true;
    };
  });
  const startRefresh = async () => {
    while (!cancelled) {
      try {
        await fn();
      } catch {
      }
      await Promise.race([
        new Promise((resolve) => setTimeout(resolve, delayMs)),
        cancellationPromise
      ]);
    }
  };
  startRefresh();
  return cancel;
}

exports.CommonDatabase = CommonDatabase;
exports.DatabaseEntitiesCatalog = DatabaseEntitiesCatalog;
exports.DatabaseLocationsCatalog = DatabaseLocationsCatalog;
exports.DatabaseManager = DatabaseManager;
exports.HigherOrderOperations = HigherOrderOperations;
exports.LocationReaders = LocationReaders;
exports.StaticEntitiesCatalog = StaticEntitiesCatalog;
exports.createRouter = createRouter;
exports.results = results;
exports.runPeriodically = runPeriodically;
